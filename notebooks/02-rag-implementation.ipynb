{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd519ef",
   "metadata": {},
   "source": [
    "### 3.1 Implement Basic Search with minsearch\n",
    "\n",
    "In this section, we implement a basic search functionality using the `minsearch` library.  \n",
    "We load the cleaned recipes dataset, convert it into a list of documents, and create a search index.  \n",
    "The index is configured to search across relevant text and keyword fields.  \n",
    "We then test the search by querying for recipes that match certain keywords (e.g., \"chicken pasta italian\") and retrieve the top results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import Index\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/recipes_clean.csv')\n",
    "\n",
    "# Create documents for indexing\n",
    "documents = df.to_dict(orient='records')\n",
    "\n",
    "# Setup minsearch index\n",
    "index = Index(\n",
    "    text_fields=['recipe_name', 'main_ingredients', 'all_ingredients', 'instructions', 'cuisine_type', 'dietary_restrictions'],\n",
    "    keyword_fields=['meal_type', 'difficulty_level']\n",
    ")\n",
    "\n",
    "# Fit the index\n",
    "index.fit(documents)\n",
    "\n",
    "# Test search\n",
    "query = \"chicken pasta italian\"\n",
    "results = index.search(query, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791e258",
   "metadata": {},
   "source": [
    "### 3.2 Implement OpenAI Integration\n",
    "\n",
    "Here, we integrate the OpenAI API to enable Retrieval-Augmented Generation (RAG).  \n",
    "We define a function to build a prompt for the language model using the search results as context.  \n",
    "The prompt instructs the model to recommend recipes based on the user's query and the retrieved recipes, providing explanations and suggesting substitutions if needed.  \n",
    "The `rag_flow` function ties everything together: it performs a search, builds the prompt, sends it to the OpenAI model, and returns the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc67e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI client using the API key from environment variables\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    \"\"\"\n",
    "    Builds a prompt for the language model using the user's query and search results.\n",
    "    The prompt includes context from the top retrieved recipes and instructs the model\n",
    "    to recommend recipes, explain matches, and suggest substitutions if needed.\n",
    "    \"\"\"\n",
    "    # Template for formatting each recipe entry in the context\n",
    "    entry_template = \"\"\"\n",
    "Recipe: {recipe_name}\n",
    "Cuisine: {cuisine_type}\n",
    "Meal Type: {meal_type}\n",
    "Difficulty: {difficulty_level}\n",
    "Prep Time: {prep_time_minutes} minutes\n",
    "Cook Time: {cook_time_minutes} minutes\n",
    "Main Ingredients: {main_ingredients}\n",
    "Instructions: {instructions}\n",
    "Dietary Info: {dietary_restrictions}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    # Combine the top search results into a single context string\n",
    "    context = \"\\n\\n\".join([entry_template.format(**doc) for doc in search_results])\n",
    "    \n",
    "    # Template for the full prompt to send to the language model\n",
    "    prompt_template = \"\"\"\n",
    "You are an expert chef and culinary assistant. Answer the question based on the content from our recipe database.\n",
    "Use only the facts from the context when answering the question.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "Provide recipe recommendations with brief explanations of why they match the requested ingredients.\n",
    "If exact ingredients aren't available, suggest the closest matches and mention any substitutions needed.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    # Return the formatted prompt with context and user question\n",
    "    return prompt_template.format(context=context, question=query)\n",
    "\n",
    "def rag_flow(query):\n",
    "    \"\"\"\n",
    "    The main RAG (Retrieval-Augmented Generation) flow:\n",
    "    1. Searches the index for relevant recipes based on the query.\n",
    "    2. Builds a prompt using the search results.\n",
    "    3. Sends the prompt to the OpenAI language model.\n",
    "    4. Returns the model's generated response.\n",
    "    \"\"\"\n",
    "    # Retrieve top 5 relevant recipes from the search index\n",
    "    search_results = index.search(query, num_results=5)\n",
    "    # Build the prompt for the language model\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    \n",
    "    # Send the prompt to the OpenAI model and get the response\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # Return the generated content from the model's response\n",
    "    return response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
