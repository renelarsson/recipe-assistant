<p align="center">
  <img src="images/banner.png" alt="Recipe Assistant Banner" width="600"/>
</p>

# ü•ó Recipe Assistant: End-to-End RAG System

## Project Objective

**Recipe Assistant** is a full-stack Retrieval-Augmented Generation (RAG) application that recommends recipes based on available ingredients. It demonstrates the complete RAG pipeline: data ingestion, retrieval, prompt engineering, LLM integration, evaluation, monitoring, and deployment‚Äîlocally and on AWS EC2.


## üß© Technologies & Procedures Used

- **LLM Integration:** Uses OpenAI GPT-4o (swappable for Ollama, Groq, AWS Bedrock, etc.) for answer generation and prompt engineering.
- **Knowledge Base:** Combines Elasticsearch (vector + keyword search) and Minsearch for hybrid retrieval, document re-ranking, and query rewriting.
- **Interfaces:** Provides a Flask API, CLI, and cURL interface.
- **Ingestion Pipelines:** Multiple approaches‚ÄîPrefect (workflow orchestration), DLT (declarative, incremental ETL), and custom Python scripts‚Äîensure reproducible, automated data loading.
- **Monitoring & Analytics:** Grafana dashboards (with Prometheus, Loki, Promtail, Tempo, and PostgreSQL) provide full observability. Prometheus scrapes and aggregates metrics from the API, CLI, and ingestion pipelines, which are visualized in Grafana alongside logs and traces. At least 5 charts are included for comprehensive monitoring (feedback, relevance, cost, response time, tokens, model usage, etc.).
- **User Feedback:** Collects and analyzes user feedback to monitor answer quality and relevance.
- **Containerization:** Docker and Docker Compose for full reproducibility and local/remote orchestration.
- **Cloud Deployment:** AWS EC2 and S3 for scalable, cloud-ready operation, with deployment scripts for one-command setup.
- **Reproducibility:** .env.template, Makefile, and Pipfile.lock ensure consistent environments and easy onboarding.
- **Best Practices:** Hybrid search, document re-ranking, query rewriting, advanced logging, and modular code structure.

---

## üß≠ Project Structure


```
recipe-assistant/
‚îú‚îÄ‚îÄ recipe_assistant/      # Main app code (API, RAG, retrieval, db, ingest)
‚îú‚îÄ‚îÄ ingestion/             # DLT pipeline, data loaders
‚îú‚îÄ‚îÄ notebooks/             # Data cleaning, RAG flow and evaluation, analytics
‚îú‚îÄ‚îÄ data/                  # Datasets, embeddings, evaluation results
‚îú‚îÄ‚îÄ grafana/               # Dashboards, provisioning, Loki/Tempo/Prometheus configs (e.g., prometheus-config.yaml)
‚îú‚îÄ‚îÄ deployment/            # AWS deployment scripts (e.g., deploy_aws.sh)
‚îú‚îÄ‚îÄ images/                # Visuals, screenshots, diagrams
‚îú‚îÄ‚îÄ logs/                  # Application logs
‚îú‚îÄ‚îÄ Makefile               # Local automation
‚îú‚îÄ‚îÄ docker-compose.yaml    # Full stack orchestration
‚îú‚îÄ‚îÄ Dockerfile             # App container
‚îú‚îÄ‚îÄ Pipfile, Pipfile.lock  # Dependency management
‚îú‚îÄ‚îÄ generate_feedback.py   # Automated feedback generation script
‚îú‚îÄ‚îÄ test.py                # API test script
‚îú‚îÄ‚îÄ plan.md                # Project plan and phases
‚îú‚îÄ‚îÄ feedback_generation_results.csv # (generated) Feedback results for dashboard analytics
‚îî‚îÄ‚îÄ README.md              # This file
```

> **Note:** `feedback_generation_results.csv` is generated by the feedback script for dashboard analytics.
## Automated Feedback Generation

To generate automated feedback for dashboard metrics, run:

```bash
python generate_feedback.py
```

This will send 100 random questions to the API, judge the answers with an LLM, and send feedback (+1/-1) accordingly. Results are saved to `feedback_generation_results.csv`.



## üèóÔ∏è Architecture Diagram

<p align="center">
  <img src="images/architecture.png" alt="Architecture Diagram" width="700"/>
</p>



## üöÄ Quickstart: Local & Remote Testing

### 1. Local Setup (WSL Ubuntu, Linux, MacOS)

#### Prerequisites
- Docker & Docker Compose
- Python 3.12, pipenv
- OpenAI API key (or compatible LLM)

#### Step-by-Step
```bash
# Clone the repo
$ git clone https://github.com/renelarsson/recipe-assistant.git
$ cd recipe-assistant

# Copy and edit environment variables
$ cp .env.template .env
$ nano .env  # Add your OpenAI key, DB creds, etc.

# Build and start all services
$ make up

# Ingest data into Elasticsearch
$ make ingest

# Initialize the database
$ make db-init

# Check API health
$ make health

# Run a test query
$ make test

# View logs
$ make applog

# Open Grafana dashboard
$ make grafana

# Run all main steps at once 
$ make all
```

### 2. Remote Deployment (AWS EC2)

#### Prerequisites
- AWS account, EC2 instance (Ubuntu 22.04+), S3 bucket (optional)
- SSH key for EC2 access

#### Step-by-Step
```bash
# SSH into your EC2 instance
$ ssh -i your-key.pem ubuntu@<ec2-public-ip>

# Clone the repo and set up environment
$ git clone https://github.com/renelarsson/recipe-assistant.git
$ cd recipe-assistant
$ cp .env.template .env
$ nano .env  # Add production secrets

# Run the deployment script
$ bash deployment/deploy_aws.sh
```
- The script installs Docker, builds the stack, waits for services, initializes DB, ingests data, runs a smoke test, and prints API/Grafana URLs.


## ÔøΩ Example Usage

### 1. Ask a Question via API and Provide Feedback
```bash
curl -X POST http://localhost:5000/question \
  -H "Content-Type: application/json" \
  -d '{"question": "What can I cook with chicken, rice, and bell pepper?"}'
```
```bash
curl -X POST http://localhost:5000/feedback \
  -H "Content-Type: application/json" \
  -d '{"conversation_id": "PASTE_ID_HERE", "feedback": 1}'
```

### 2. Interact via CLI
```bash
python recipe_assistant/cli.py --question "What can I cook with chicken, rice, and bell pepper?"
# or, for interactive mode:
python recipe_assistant/cli.py
# (Follow the prompts to enter your ingredients, questions and feedback)
```

### 3. Export Data from Postgres
```bash
make db-shell
# Inside the container:
\copy (SELECT * FROM conversations LIMIT 5) TO 'conversations.csv' CSV HEADER
\copy (SELECT * FROM feedback LIMIT 5) TO 'feedback.csv' CSV HEADER
```



## ‚öôÔ∏è Makefile Targets (Local Automation)

| Target      | Description                                      |
|-------------|--------------------------------------------------|
| all         | Run all main steps (up, ingest, db-init, health, test, lint) |
| up          | Build and start all services (Docker Compose)     |
| stop        | Stop all running containers                       |
| down        | Stop and remove all services, networks, volumes   |
| build       | Build Docker images only                          |
| restart     | Restart app and grafana containers                |
| logs        | Show all container logs                           |
| app-shell   | Open bash shell in app container                  |
| db-shell    | Open bash shell in postgres container             |
| ingest      | Ingest data into Elasticsearch                    |
| db-init     | Initialize/reset the PostgreSQL database          |
| health      | Check API health endpoint                         |
| dlt         | Run DLT pipeline (analytics data)                 |
| test        | Run test script (API check)                       |
| lint        | Lint Python code with flake8                      |
| applog      | Show application logs (logs/app.log)              |
| grafana     | Open Grafana dashboard in browser                 |

---
## Monitoring Dashboard

![Recipe Assistant Dashboard](images/dashboard.png)

---

## üìÑ License & Attribution

This project is a capstone for the [LLM Zoomcamp](https://datatalks.club/) at DataTalks.Club.
See the main course repo: https://github.com/DataTalksClub/llm-zoomcamp
